name: Active Players Web Scrape Pipeline

on:
  schedule:
    - cron: '*/15 * * * *' # runs every 15 minutes
  workflow_dispatch:       # optional manual trigger

env:
  MYSQL_USER:    ${{ secrets.MYSQL_USER }}
  MYSQL_PASSWORD: ${{ secrets.MYSQL_PASSWORD }}
  MYSQL_HOST:    ${{ secrets.MYSQL_HOST }}
  MYSQL_DB:      ${{ secrets.MYSQL_DB }}
  PG_USER:       ${{ secrets.PG_USER }}
  PG_PASSWORD:   ${{ secrets.PG_PASSWORD }}
  PG_HOST:       ${{ secrets.PG_HOST }}
  PG_DB:         ${{ secrets.PG_DB }}

jobs:
  run_web_scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install papermill

      - name: Run web scrape notebook
        run: |
          papermill notebooks/Active_Players_Web_Scrape_Extract_Load_Raw.py notebooks/output_scrape.py
